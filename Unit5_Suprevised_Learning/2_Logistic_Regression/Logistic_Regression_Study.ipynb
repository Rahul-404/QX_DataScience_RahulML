{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üåü Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression is one of the basic and popular algorithm to solve a classification problem. It is named as ‚ÄòLogistic Regression‚Äô, because it‚Äôs underlying technique is quite the same as Linear Regression. The term ‚ÄúLogistic‚Äù is taken from the <b>Logit function</b> that is used in this method of classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression was used in the biological sciences in early twentieth century. It was then used in many social science applications. <b>Logistic Regression is used when the dependent variable(target) is categorical.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>To predict whether an email is spam (1) or (0)</li>\n",
    "    <li>Whether the tumor is malignant (1) or not (0)</li>\n",
    "</ul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a scenario where we need to classify whether an email is spam or not. If we use linear regression for this problem, there is a need for setting up a threshold based on which classification can be done. Say if the actual class is malignant, predicted continuous value 0.4 and the threshold value is 0.5, the data point will be classified as not malignant which can lead to serious consequence in real time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this example, it can be inferred that linear regression is not suitable for classification problem. Linear regression is unbounded, and this brings logistic regression into picture. Their value strictly ranges from 0 to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚≠ïÔ∏è Important Terminology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Decision Boundary?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision boundary helps to differentiate probabilities into positive class and negative class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Decision Boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/logistic_regression_9.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/logistic_regression_10.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non Linear Decision Boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/logistic_regression_11.png'>\n",
    "<img src='img/logistic_regression_12.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚ùìHow does it work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression uses Sigmoid function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An explanation of logistic regression can begin with an explanation of the standard logistic function. The logistic function is a Sigmoid function, which takes any real value between zero and one. It is defined as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/logistic_regression_1.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if we plot it, the graph will be S curve,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/logistic_regression_2.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let‚Äôs consider t as linear function in a univariate regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/logistic_regression_3.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the Logistic Equation will become"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/logistic_regression_4.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, when logistic regression model come across an outlier, it will take care of it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/logistic_regression_5.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But sometime it will shift its y axis to left or right depending on outliers positions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîä Questions and Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why not use Linear Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have a data of tumor size vs its malignancy. As it is a classification problem, if we plot, we can see, all the values will lie on 0 and 1. And if we fit best found regression line, by assuming the threshold at 0.5, we can do line pretty reasonable job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/logistic_regression_6.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can decide the point on the x axis from where all the values lie to its left side are considered as negative class and all the values lie to its right side are positive class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/logistic_regression_7.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what if there is an outlier in the data. Things would get pretty messy. For example, for 0.5 threshold,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/logistic_regression_8.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we fit best found regression line, it still won‚Äôt be enough to decide any point by which we can differentiate classes. It will put some positive class examples into negative class. The green dotted line (Decision Boundary) is dividing malignant tumors from benign tumors but the line should have been at a yellow line which is clearly dividing the positive and negative examples. So just a single outlier is disturbing the whole linear regression predictions. And that is where logistic regression comes into a picture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚öîÔ∏è Advantage & Disadvantages of Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advantages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<ul>\n",
    "    <li>Logistic Regression is <b>one of the simplest machine learning algorithms</b> and is easy to implement yet provides great training efficiency in some cases. Also due to these reasons, training a model with this algorithm doesn't require high computation power.</li>\n",
    "    <li>The predicted parameters (trained weights) give <b>inference about the importance of each feature.</b> The direction of association i.e. positive or negative is also given. So we can use logistic regression to find out the relationship between the features.</li>\n",
    "    <li>In a <b>low dimensional dataset</b> having a sufficient number of training examples, logistic regression is <b>less prone to over-fitting.</b></li>\n",
    "    <li>Logistic Regression proves to be <b>very efficient</b> when the dataset has <b>features that are linearly separable.</b></li>\n",
    "    <li>Due to its simple probabilistic interpretation, the <b>training time</b> of logistic regression algorithm comes out to be far <b>less than most complex algorithms</b>, such as an Artificial Neural Network.</li>\n",
    "    <li>This algorithm <b>can easily be extended to multi-class classification</b> using a softmax classifier, this is known as Multinomial Logistic Regression.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disadvantages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>On <b>high dimensional datasets,</b> this may lead to the model being <b>over-fit on the training set,</b> which means overstating the accuracy of predictions on the training set and thus the model <b>may not be able to predict accurate results on the test set.</b></li>\n",
    "    <li><b>Non linear problems can't be solved</b> with logistic regression <b>since it has a linear decision surface.</b></li>\n",
    "    <li>The presence of data values that deviate from the expected range in the dataset may lead to incorrect results as this algorithm is <b>sensitive to outliers.</b></li>\n",
    "    <li>Logistic Regression <b>requires a large dataset</b> and also sufficient training examples for all the categories it needs to identify.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîó Assumptions of logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li><b>Dependent variable is binary:</b> If this is not true, then logistic regression outputs do not apply.</li>\n",
    "    <li><b>Linearity between logit and independent variables:</b> This follows from equation A ‚Äî if this condition is not met, logistic regression is invalid.</li>\n",
    "    <li><b>No multicollinearity:</b> Multicollinearity distorts tests of statistical significance on regression coefficients.</li>\n",
    "    <li><b>Large sample size:</b> This is more of a rule of thumb.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A nice to have here is that your data has a balanced number of classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLS assumptions that don‚Äôt apply to logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li><b>Linearity between dependent and independent variables</b></li>\n",
    "    <li><b>Normal residuals</b></li>\n",
    "    <li><b>Homoskedasticity</b></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìä Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check the performance, we can use <b>confusion matrix</b> and <b>AUC - ROC</b> Curve. To know what it is,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü§ñ Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression is a powerful machine learning algorithm that utilizes a sigmoid function and works best on binary classification problems, although it can be used on multi-class classification problems through the ‚Äúone vs. all‚Äù method. <b>Logistic regression (despite its name) is not fit for regression tasks.</b> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
